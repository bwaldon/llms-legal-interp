\begin{tabular}{lrrrr}
\toprule
 & Covered & NotCovered & Min & Max \\
Model &  &  &  &  \\
\midrule
Llama-3.2-1B & 138 & 0 & 0.06 & 0.29 \\
Llama-3.2-1B-Instruct & 138 & 0 & 0.15 & 0.59 \\
Llama-3.2-3B & 127 & 11 & 0.09 & 0.52 \\
Llama-3.2-3B-Instruct & 53 & 85 & 0.16 & 0.69 \\
Llama-3.1-8B & 80 & 58 & 0.14 & 0.37 \\
Llama-3.1-8B-Instruct & 0 & 138 & 0.11 & 0.74 \\
Llama-3.3-70B-Instruct & 59 & 79 & 0.02 & 0.85 \\
gpt2-medium & 5 & 133 & 0.13 & 0.31 \\
OLMo-2-1124-7B & 70 & 68 & 0.19 & 0.56 \\
OLMo-2-1124-7B-Instruct & 53 & 85 & 0.00 & 0.99 \\
Ministral-8B-Instruct-2410 & 75 & 63 & 0.21 & 0.59 \\
gemma-7b & 39 & 99 & 0.19 & 0.49 \\
gemma-7b-it & 131 & 7 & 0.00 & 1.00 \\
openai-gpt-4 & 77 & 61 & 0.00 & 1.00 \\
\bottomrule
\end{tabular}
