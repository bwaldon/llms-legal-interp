\begin{tabular}{lrrrr}
\toprule
 & Covered & NotCovered & Min & Max \\
Model &  &  &  &  \\
\midrule
Llama-3.2-1B & 138 & 0 & 0.06 & 0.27 \\
Llama-3.2-1B-Instruct & 138 & 0 & 0.13 & 0.50 \\
Llama-3.2-3B & 129 & 9 & 0.08 & 0.50 \\
Llama-3.2-3B-Instruct & 51 & 87 & 0.15 & 0.65 \\
Llama-3.1-8B & 75 & 63 & 0.12 & 0.34 \\
Llama-3.1-8B-Instruct & 0 & 138 & 0.09 & 0.70 \\
Llama-3.3-70B-Instruct & 59 & 79 & 0.02 & 0.81 \\
gpt2-medium & 5 & 133 & 0.12 & 0.30 \\
OLMo-2-1124-7B & 73 & 65 & 0.18 & 0.56 \\
OLMo-2-1124-7B-Instruct & 53 & 85 & 0.00 & 0.99 \\
Ministral-8B-Instruct-2410 & 87 & 51 & 0.20 & 0.58 \\
gemma-7b & 48 & 90 & 0.17 & 0.43 \\
gemma-7b-it & 131 & 7 & 0.00 & 0.99 \\
openai-gpt-4 & 52 & 86 & 0.00 & 0.47 \\
\bottomrule
\end{tabular}
