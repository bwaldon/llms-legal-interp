{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f686275-e737-48cb-8418-0517544d80b6",
   "metadata": {},
   "source": [
    "# Analysis of Model judgments for robustness to question variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6bac8a-b54e-4977-a2be-621ee695953f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekp/miniconda3/envs/prej_prompt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import output_processing as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9401804b-721b-48f4-8f82-57e88d0337dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    # Main set of models with instruct divide and size variety\n",
    "    \"meta-llama/Llama-3.2-1B\",\n",
    "    \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    \"meta-llama/Llama-3.2-3B\",\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    \"meta-llama/Llama-3.1-8B\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    # Small reference model - would allow for pretraining variation\n",
    "    \"gpt2-medium\",\n",
    "    # Other open models\n",
    "    \"allenai/OLMo-2-1124-7B\",\n",
    "    \"allenai/OLMo-2-1124-7B-Instruct\",\n",
    "    \"mistralai/Ministral-8B-Instruct-2410\",\n",
    "    \"google/gemma-7b\",\n",
    "    \"google/gemma-7b-it\",\n",
    "    # Large platform model\n",
    "    \"openai-gpt-4\",\n",
    "]\n",
    "\n",
    "def read_and_organize_model_results(model_name):\n",
    "    model_results = pd.read_csv(f\"runs/runs-42_07_16/{model_name}-results.csv\")\n",
    "    # model_results.replace([0.0], -65504, inplace=True)\n",
    "    model_results = op.organize_distribution(model_results)\n",
    "    model_results[\"model_name\"] = model_name.split(\"/\")[-1]\n",
    "    model_results.loc[model_results[\"Covered\"] == True, \"Judgment\"] = \"Covered\"\n",
    "    model_results.loc[model_results[\"Covered\"] == True, \"Judgment_prob\"] = model_results[\"Covered_prob\"]\n",
    "    model_results.loc[model_results[\"NotCovered\"] == True, \"Judgment\"] = \"NotCovered\"\n",
    "    model_results.loc[model_results[\"NotCovered\"] == True, \"Judgment_prob\"] = model_results[\"NotCovered_prob\"]\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0d8896-23da-461a-a999-841429dc9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO organize the output for better clarity\n",
    "combined_results = [read_and_organize_model_results(model_name) for model_name in model_list]\n",
    "combined_df = pd.concat(combined_results).reset_index()\n",
    "combined_df.loc[:, \"item\"] = combined_df[\"title\"] + combined_df[\"version\"]\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b8e0dd0-ef6d-4d48-a568-6a2dabe43d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Llama-3.2-1B' 'Llama-3.2-1B-Instruct' 'Llama-3.2-3B'\n",
      " 'Llama-3.2-3B-Instruct' 'Llama-3.1-8B' 'Llama-3.1-8B-Instruct'\n",
      " 'Llama-3.3-70B-Instruct' 'gpt2-medium' 'OLMo-2-1124-7B'\n",
      " 'OLMo-2-1124-7B-Instruct' 'Ministral-8B-Instruct-2410' 'gemma-7b'\n",
      " 'gemma-7b-it' 'openai-gpt-4']\n"
     ]
    }
   ],
   "source": [
    "# Print summary of the experimental results\n",
    "print(combined_df.model_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f361805c-16d9-41dd-9072-b5964dfd6b68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>version</th>\n",
       "      <th>output</th>\n",
       "      <th>output_text</th>\n",
       "      <th>cum_logprob</th>\n",
       "      <th>YES_probs</th>\n",
       "      <th>Yes_probs</th>\n",
       "      <th>...</th>\n",
       "      <th>UnAff_prob</th>\n",
       "      <th>Covered_prob</th>\n",
       "      <th>NotCovered_prob</th>\n",
       "      <th>Covered</th>\n",
       "      <th>NotCovered</th>\n",
       "      <th>entropy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>Judgment</th>\n",
       "      <th>Judgment_prob</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>908</td>\n",
       "      <td>Wind Damage</td>\n",
       "      <td>disagreement_negation</td>\n",
       "      <td>Tom's home insurance policy includes coverage ...</td>\n",
       "      <td>controversial</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.440817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302091</td>\n",
       "      <td>0.440817</td>\n",
       "      <td>0.302091</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.071909</td>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>Covered</td>\n",
       "      <td>0.440817</td>\n",
       "      <td>Wind Damagecontroversial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        title            prompt_type  \\\n",
       "2150    908  Wind Damage  disagreement_negation   \n",
       "\n",
       "                                                 prompt        version output  \\\n",
       "2150  Tom's home insurance policy includes coverage ...  controversial    yes   \n",
       "\n",
       "     output_text  cum_logprob  YES_probs  Yes_probs  ...  UnAff_prob  \\\n",
       "2150        yes.          NaN   0.072278   0.440817  ...    0.302091   \n",
       "\n",
       "      Covered_prob  NotCovered_prob  Covered  NotCovered   entropy  \\\n",
       "2150      0.440817         0.302091     True       False  1.071909   \n",
       "\n",
       "                 model_name  Judgment  Judgment_prob                      item  \n",
       "2150  Llama-3.2-1B-Instruct   Covered       0.440817  Wind Damagecontroversial  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at one of the result samples\n",
    "combined_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb6b33-e77b-4368-bba5-895f0405bcec",
   "metadata": {},
   "source": [
    "## Prepare the table with Categorical counts and Distributional Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbf877e-1aa7-4249-8e15-aecae113db7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Covered</th>\n",
       "      <th>NotCovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>127</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>80</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.3-70B-Instruct</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OLMo-2-1124-7B</td>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OLMo-2-1124-7B-Instruct</td>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>75</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>39</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gemma-7b-it</td>\n",
       "      <td>131</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai-gpt-4</td>\n",
       "      <td>77</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Covered  NotCovered\n",
       "0                 Llama-3.2-1B      138           0\n",
       "1        Llama-3.2-1B-Instruct      138           0\n",
       "2                 Llama-3.2-3B      127          11\n",
       "3        Llama-3.2-3B-Instruct       53          85\n",
       "4                 Llama-3.1-8B       80          58\n",
       "5        Llama-3.1-8B-Instruct        0         138\n",
       "6       Llama-3.3-70B-Instruct       59          79\n",
       "7                  gpt2-medium        5         133\n",
       "8               OLMo-2-1124-7B       70          68\n",
       "9      OLMo-2-1124-7B-Instruct       53          85\n",
       "10  Ministral-8B-Instruct-2410       75          63\n",
       "11                    gemma-7b       39          99\n",
       "12                 gemma-7b-it      131           7\n",
       "13                openai-gpt-4       77          61"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical Counts for Yes/No question variant\n",
    "question_variant_mask = combined_df[\"prompt_type\"] == \"yes_or_no\"\n",
    "yes_or_no_df = combined_df[question_variant_mask]\n",
    "count_labels = yes_or_no_df.groupby('model_name', as_index=False, sort=False).aggregate(\n",
    "    {\n",
    "        'Covered': 'sum',\n",
    "        'NotCovered': 'sum',\n",
    "    }\n",
    ")\n",
    "count_labels = count_labels.rename({'model_name' : 'Model'}, axis=1)\n",
    "count_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fb6a52-8faa-4fb8-9e94-a01fa78aedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latex table just for categorical counts\n",
    "count_labels.to_latex(\"reports/yes_or_no_categorical_counts.tex\", index=True, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe0f958-b2cb-43bc-975d-110edd4e7c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.3-70B-Instruct</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OLMo-2-1124-7B</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OLMo-2-1124-7B-Instruct</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gemma-7b-it</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai-gpt-4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model    Min    Max\n",
       "0                 Llama-3.1-8B  0.138  0.367\n",
       "1        Llama-3.1-8B-Instruct  0.110  0.742\n",
       "2                 Llama-3.2-1B  0.064  0.291\n",
       "3        Llama-3.2-1B-Instruct  0.151  0.592\n",
       "4                 Llama-3.2-3B  0.093  0.517\n",
       "5        Llama-3.2-3B-Instruct  0.159  0.690\n",
       "6       Llama-3.3-70B-Instruct  0.022  0.849\n",
       "7   Ministral-8B-Instruct-2410  0.211  0.595\n",
       "8               OLMo-2-1124-7B  0.190  0.564\n",
       "9      OLMo-2-1124-7B-Instruct  0.001  0.991\n",
       "10                    gemma-7b  0.191  0.490\n",
       "11                 gemma-7b-it  0.000  1.002\n",
       "12                 gpt2-medium  0.129  0.308\n",
       "13                openai-gpt-4  0.000  1.000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distributional spread for Yes/No question variant\n",
    "question_variant_mask = combined_df[\"prompt_type\"] == \"yes_or_no\"\n",
    "yes_or_no_df = combined_df[question_variant_mask]\n",
    "\n",
    "# Util function\n",
    "yes_or_no_judgement_range = yes_or_no_df[['model_name', 'Covered_prob', 'NotCovered_prob']].melt(id_vars='model_name', value_vars=['Covered_prob', 'NotCovered_prob']).groupby('model_name', as_index=False).agg(\n",
    "    Min = pd.NamedAgg('value', lambda x: np.round(np.min(x), 3)),\n",
    "    Max = pd.NamedAgg('value', lambda x: np.round(np.max(x), 3)),\n",
    "    ).rename({\"model_name\": \"Model\"}, axis=1)\n",
    "\n",
    "yes_or_no_judgement_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14453bca-0415-4def-9514-86382dc64fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate latex table for yes_or_no judgement range\n",
    "yes_or_no_judgement_range.to_latex(\"reports/yes_or_no_distributional_spread.tex\", index=True, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffcd39d-7723-4757-aabd-3f9ae1d5908a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Covered</th>\n",
       "      <th>NotCovered</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B</th>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B</th>\n",
       "      <td>127</td>\n",
       "      <td>11</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>80</td>\n",
       "      <td>58</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.3-70B-Instruct</th>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B</th>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B-Instruct</th>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ministral-8B-Instruct-2410</th>\n",
       "      <td>75</td>\n",
       "      <td>63</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>39</td>\n",
       "      <td>99</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>131</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt-4</th>\n",
       "      <td>77</td>\n",
       "      <td>61</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Covered  NotCovered    Min    Max\n",
       "Model                                                        \n",
       "Llama-3.2-1B                    138           0  0.064  0.291\n",
       "Llama-3.2-1B-Instruct           138           0  0.151  0.592\n",
       "Llama-3.2-3B                    127          11  0.093  0.517\n",
       "Llama-3.2-3B-Instruct            53          85  0.159  0.690\n",
       "Llama-3.1-8B                     80          58  0.138  0.367\n",
       "Llama-3.1-8B-Instruct             0         138  0.110  0.742\n",
       "Llama-3.3-70B-Instruct           59          79  0.022  0.849\n",
       "gpt2-medium                       5         133  0.129  0.308\n",
       "OLMo-2-1124-7B                   70          68  0.190  0.564\n",
       "OLMo-2-1124-7B-Instruct          53          85  0.001  0.991\n",
       "Ministral-8B-Instruct-2410       75          63  0.211  0.595\n",
       "gemma-7b                         39          99  0.191  0.490\n",
       "gemma-7b-it                     131           7  0.000  1.002\n",
       "openai-gpt-4                     77          61  0.000  1.000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combined table\n",
    "# Merge the two tables\n",
    "yes_or_no_table = pd.concat([count_labels.set_index('Model'), yes_or_no_judgement_range.set_index('Model')], axis=1, join='inner')\n",
    "yes_or_no_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccda140a-06e8-440b-ae9a-29cc00496c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_or_no_table.to_latex(\"reports/yes_or_no_table.tex\", index=True, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023c2942-6326-46c2-af17-68b6dcb59f2f",
   "metadata": {},
   "source": [
    "## Prepare the majority votes frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c13f17-e30e-4e67-9a0a-4a1da450c777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Majority Count</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>40.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>6.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B</th>\n",
       "      <td>12.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>129.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B</th>\n",
       "      <td>95.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>75.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.3-70B-Instruct</th>\n",
       "      <td>25.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ministral-8B-Instruct-2410</th>\n",
       "      <td>24.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B</th>\n",
       "      <td>46.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B-Instruct</th>\n",
       "      <td>51.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>44.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>9.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>50.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt-4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Frequency                       \n",
       "Majority Count                     5     6     7     8    9\n",
       "Model                                                      \n",
       "Llama-3.1-8B                    40.0  52.0  46.0   0.0  0.0\n",
       "Llama-3.1-8B-Instruct            6.0  39.0  59.0  31.0  3.0\n",
       "Llama-3.2-1B                    12.0  57.0  69.0   0.0  0.0\n",
       "Llama-3.2-1B-Instruct          129.0   9.0   0.0   0.0  0.0\n",
       "Llama-3.2-3B                    95.0  40.0   3.0   0.0  0.0\n",
       "Llama-3.2-3B-Instruct           75.0  48.0  15.0   0.0  0.0\n",
       "Llama-3.3-70B-Instruct          25.0  33.0  78.0   2.0  0.0\n",
       "Ministral-8B-Instruct-2410      24.0  65.0  30.0  18.0  1.0\n",
       "OLMo-2-1124-7B                  46.0  65.0  20.0   7.0  0.0\n",
       "OLMo-2-1124-7B-Instruct         51.0  57.0  30.0   0.0  0.0\n",
       "gemma-7b                        44.0  58.0  29.0   7.0  0.0\n",
       "gemma-7b-it                      9.0  31.0  79.0  19.0  0.0\n",
       "gpt2-medium                     50.0  83.0   5.0   0.0  0.0\n",
       "openai-gpt-4                     4.0   9.0  57.0  63.0  5.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the majority votes\n",
    "majority_vote_by_model = combined_df.groupby(['title', 'version', 'model_name'], as_index=False, sort=False).aggregate(\n",
    "     {\n",
    "        'Covered': 'sum',\n",
    "        'NotCovered': 'sum',\n",
    "    }\n",
    ")\n",
    "majority_vote_by_model.loc[:, \"majority_count\"] = majority_vote_by_model[['Covered', 'NotCovered']].max(axis=1)\n",
    "majority_vote_by_model.shape\n",
    "majority_vote_table_df = majority_vote_by_model[[\"model_name\", \"majority_count\"]].value_counts().reset_index(name=\"Frequency\")\\\n",
    ".pivot_table(columns =['majority_count'], index=\"model_name\", aggfunc=\"sum\", margins=True)\\\n",
    "\n",
    "majority_vote_table_df.replace(np.nan, 0, inplace=True)\n",
    "# Remove the \"All\" from columns and rows\n",
    "majority_vote_table_df = majority_vote_table_df.drop([\"All\"], axis=0)\n",
    "majority_vote_table_df = majority_vote_table_df.drop([(\"Frequency\", \"All\")], axis=1)\n",
    "\n",
    "majority_vote_table_df = majority_vote_table_df.rename({'model_name': 'Model', 'majority_count': 'Majority Count'})\n",
    "majority_vote_table_df.index = majority_vote_table_df.index.rename('Model')\n",
    "majority_vote_table_df.columns.names = [None, 'Majority Count']\n",
    "majority_vote_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f15ef0da-baba-4922-b689-2c51b60bfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_vote_table_df.to_latex(\"reports/majority-votes-freq-table.tex\", float_format=\"%.0f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4ea87-1e71-42f9-a347-8f040ff0ac0f",
   "metadata": {},
   "source": [
    "## Minority responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0726f6a-f6f8-4daf-9e55-25cd1bd57764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5565, 17388)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minority responses\n",
    "combined_df.loc[combined_df.Covered == True, \"judgment\"] = \"Covered\"\n",
    "combined_df.loc[combined_df.NotCovered == True, \"judgment\"] = \"Not Covered\"\n",
    "majority_vote_by_model.loc[:, \"majority\"] = majority_vote_by_model.apply(lambda x: \"Covered\" if x.Covered >= x.NotCovered else \"Not Covered\",  axis=1)\n",
    "combined_df.loc[:, \"in_minority\"]= False\n",
    "for index, row in majority_vote_by_model.iterrows():\n",
    "    item_model_mask = (combined_df[\"title\"] == row.title) & (combined_df[\"version\"] == row.version) & (combined_df[\"model_name\"] == row.model_name)\n",
    "    in_minority_mask = combined_df[\"judgment\"]!= row.majority\n",
    "    combined_df.loc[item_model_mask & in_minority_mask, \"in_minority\"] = True\n",
    "\n",
    "combined_df.in_minority.sum(), combined_df.shape[0]\n",
    "\n",
    "## Minority responses by question variants for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "927103bb-1794-4547-9837-b2a90deea2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_responses = combined_df[combined_df.in_minority == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed34c03-4dec-4b7a-9a32-42ba38b73edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"9\" halign=\"left\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_type</th>\n",
       "      <th>agreement</th>\n",
       "      <th>agreement_negation</th>\n",
       "      <th>disagreement</th>\n",
       "      <th>disagreement_negation</th>\n",
       "      <th>negation</th>\n",
       "      <th>no_or_yes</th>\n",
       "      <th>options</th>\n",
       "      <th>options_flipped</th>\n",
       "      <th>yes_or_no</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>21.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>13.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B</th>\n",
       "      <td>123.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>47.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.3-70B-Instruct</th>\n",
       "      <td>14.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ministral-8B-Instruct-2410</th>\n",
       "      <td>10.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B</th>\n",
       "      <td>68.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B-Instruct</th>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>17.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>124.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt-4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count                                  \\\n",
       "prompt_type                agreement agreement_negation disagreement   \n",
       "model_name                                                             \n",
       "Llama-3.1-8B                    21.0              101.0        112.0   \n",
       "Llama-3.1-8B-Instruct            5.0               29.0         58.0   \n",
       "Llama-3.2-1B                     0.0              138.0        138.0   \n",
       "Llama-3.2-1B-Instruct           13.0              125.0        125.0   \n",
       "Llama-3.2-3B                   123.0              137.0        104.0   \n",
       "Llama-3.2-3B-Instruct           47.0               74.0         74.0   \n",
       "Llama-3.3-70B-Instruct          14.0               57.0         46.0   \n",
       "Ministral-8B-Instruct-2410      10.0               48.0         75.0   \n",
       "OLMo-2-1124-7B                  68.0               63.0         65.0   \n",
       "OLMo-2-1124-7B-Instruct         34.0               68.0        106.0   \n",
       "gemma-7b                        17.0               64.0         88.0   \n",
       "gemma-7b-it                      7.0                5.0        127.0   \n",
       "gpt2-medium                    124.0               14.0         14.0   \n",
       "openai-gpt-4                     3.0               24.0         53.0   \n",
       "\n",
       "                                                                             \\\n",
       "prompt_type                disagreement_negation negation no_or_yes options   \n",
       "model_name                                                                    \n",
       "Llama-3.1-8B                                37.0     29.0      16.0    33.0   \n",
       "Llama-3.1-8B-Instruct                       74.0     32.0       1.0     1.0   \n",
       "Llama-3.2-1B                                 0.0      0.0      16.0    48.0   \n",
       "Llama-3.2-1B-Instruct                       13.0      0.0     125.0   116.0   \n",
       "Llama-3.2-3B                                 2.0      1.0       1.0   127.0   \n",
       "Llama-3.2-3B-Instruct                       64.0     41.0      29.0    65.0   \n",
       "Llama-3.3-70B-Instruct                      89.0     99.0      11.0    19.0   \n",
       "Ministral-8B-Instruct-2410                  70.0     61.0       7.0    72.0   \n",
       "OLMo-2-1124-7B                              61.0     27.0      21.0    44.0   \n",
       "OLMo-2-1124-7B-Instruct                     70.0     48.0       9.0    26.0   \n",
       "gemma-7b                                    53.0     32.0      14.0    63.0   \n",
       "gemma-7b-it                                101.0     23.0       5.0     5.0   \n",
       "gpt2-medium                                124.0     41.0       4.0    90.0   \n",
       "openai-gpt-4                                87.0     41.0       2.0     4.0   \n",
       "\n",
       "                                                      \n",
       "prompt_type                options_flipped yes_or_no  \n",
       "model_name                                            \n",
       "Llama-3.1-8B                          30.0      29.0  \n",
       "Llama-3.1-8B-Instruct                 89.0       1.0  \n",
       "Llama-3.2-1B                          17.0       0.0  \n",
       "Llama-3.2-1B-Instruct                 13.0      13.0  \n",
       "Llama-3.2-3B                           1.0      10.0  \n",
       "Llama-3.2-3B-Instruct                 57.0      23.0  \n",
       "Llama-3.3-70B-Instruct                18.0       4.0  \n",
       "Ministral-8B-Instruct-2410            17.0       9.0  \n",
       "OLMo-2-1124-7B                        66.0      11.0  \n",
       "OLMo-2-1124-7B-Instruct               57.0      17.0  \n",
       "gemma-7b                              38.0      46.0  \n",
       "gemma-7b-it                           31.0       2.0  \n",
       "gpt2-medium                           39.0       9.0  \n",
       "openai-gpt-4                           3.0       3.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_pivot = minority_responses[[\"model_name\", \"prompt_type\"]].value_counts().reset_index().pivot_table(index=\"model_name\", columns=\"prompt_type\")\n",
    "minority_pivot.replace(np.nan, 0, inplace=True)\n",
    "minority_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663bf788-ef3c-4983-b07a-d59c76414b73",
   "metadata": {},
   "source": [
    "## Minority responses by question variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df101ba8-176d-47d3-ba2d-d795e0beff25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5565, 17388)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minority responses\n",
    "combined_df.loc[combined_df.Covered == True, \"judgment\"] = \"Covered\"\n",
    "combined_df.loc[combined_df.NotCovered == True, \"judgment\"] = \"Not Covered\"\n",
    "majority_vote_by_model.loc[:, \"majority\"] = majority_vote_by_model.apply(lambda x: \"Covered\" if x.Covered >= x.NotCovered else \"Not Covered\",  axis=1)\n",
    "combined_df.loc[:, \"in_minority\"]= False\n",
    "for index, row in majority_vote_by_model.iterrows():\n",
    "    item_model_mask = (combined_df[\"title\"] == row.title) & (combined_df[\"version\"] == row.version) & (combined_df[\"model_name\"] == row.model_name)\n",
    "    in_minority_mask = combined_df[\"judgment\"]!= row.majority\n",
    "    combined_df.loc[item_model_mask & in_minority_mask, \"in_minority\"] = True\n",
    "\n",
    "combined_df.in_minority.sum(), combined_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09dc0c33-a348-4cba-9de0-0e2868263dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disagreement</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agreement_negation</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disagreement_negation</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>options</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agreement</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>options_flipped</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negation</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no_or_yes</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yes_or_no</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prompt_type  count\n",
       "0           disagreement   1185\n",
       "1     agreement_negation    947\n",
       "2  disagreement_negation    845\n",
       "3                options    713\n",
       "4              agreement    486\n",
       "5        options_flipped    476\n",
       "6               negation    475\n",
       "7              no_or_yes    261\n",
       "8              yes_or_no    177"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_responses = combined_df[combined_df.in_minority == True]\n",
    "minority_responses[[\"prompt_type\"]].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5d7043a-8825-4216-9b3d-1cf02b962c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disagreement</td>\n",
       "      <td>0.212938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agreement_negation</td>\n",
       "      <td>0.170171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disagreement_negation</td>\n",
       "      <td>0.151842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>options</td>\n",
       "      <td>0.128122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agreement</td>\n",
       "      <td>0.087332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>options_flipped</td>\n",
       "      <td>0.085535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negation</td>\n",
       "      <td>0.085355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no_or_yes</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yes_or_no</td>\n",
       "      <td>0.031806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prompt_type     count\n",
       "0           disagreement  0.212938\n",
       "1     agreement_negation  0.170171\n",
       "2  disagreement_negation  0.151842\n",
       "3                options  0.128122\n",
       "4              agreement  0.087332\n",
       "5        options_flipped  0.085535\n",
       "6               negation  0.085355\n",
       "7              no_or_yes  0.046900\n",
       "8              yes_or_no  0.031806"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(minority_responses[[\"prompt_type\"]].value_counts()/minority_responses.shape[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a27ff17f-d7be-443d-aba5-9c6a1c5e776a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>disagreement</th>\n",
       "      <td>1185</td>\n",
       "      <td>0.212938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agreement_negation</th>\n",
       "      <td>947</td>\n",
       "      <td>0.170171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disagreement_negation</th>\n",
       "      <td>845</td>\n",
       "      <td>0.151842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>options</th>\n",
       "      <td>713</td>\n",
       "      <td>0.128122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agreement</th>\n",
       "      <td>486</td>\n",
       "      <td>0.087332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>options_flipped</th>\n",
       "      <td>476</td>\n",
       "      <td>0.085535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negation</th>\n",
       "      <td>475</td>\n",
       "      <td>0.085355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_or_yes</th>\n",
       "      <td>261</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes_or_no</th>\n",
       "      <td>177</td>\n",
       "      <td>0.031806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Count  Proportion\n",
       "prompt_type                             \n",
       "disagreement            1185    0.212938\n",
       "agreement_negation       947    0.170171\n",
       "disagreement_negation    845    0.151842\n",
       "options                  713    0.128122\n",
       "agreement                486    0.087332\n",
       "options_flipped          476    0.085535\n",
       "negation                 475    0.085355\n",
       "no_or_yes                261    0.046900\n",
       "yes_or_no                177    0.031806"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_counts = minority_responses[[\"prompt_type\"]].value_counts().reset_index().set_index(\"prompt_type\")\n",
    "minority_counts.columns = ['Count']\n",
    "minority_props = (minority_counts/minority_responses.shape[0]).reset_index().set_index(\"prompt_type\")\n",
    "minority_props.columns = ['Proportion']\n",
    "pd.concat([minority_counts, minority_props], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb46f342-1961-4f6c-855c-729b50377a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Count', 'Proportion'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([minority_counts, minority_props], axis=1, join='inner').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbebf0-3e67-4fe3-983d-0fb3f2144b28",
   "metadata": {},
   "source": [
    "## Make the table for Jensen-Shannon Distance for non Yes/No question variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd7996cc-aec9-47bb-b237-dae63b97eaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>version</th>\n",
       "      <th>model_name</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>js_dist</th>\n",
       "      <th>kl_div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10075</th>\n",
       "      <td>Escape of Water II</td>\n",
       "      <td>controversial</td>\n",
       "      <td>OLMo-2-1124-7B-Instruct</td>\n",
       "      <td>agreement_negation</td>\n",
       "      <td>0.056223</td>\n",
       "      <td>0.011105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title        version               model_name  \\\n",
       "10075  Escape of Water II  controversial  OLMo-2-1124-7B-Instruct   \n",
       "\n",
       "              prompt_type   js_dist    kl_div  \n",
       "10075  agreement_negation  0.056223  0.011105  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divergences = op.calculate_relative_measures(combined_df)\n",
    "divergences.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11fc7a9f-ac77-4f48-99fd-ebaecb242ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "js_dist\n",
       "inf         443\n",
       "0.044400      1\n",
       "0.797847      1\n",
       "0.015075      1\n",
       "0.832481      1\n",
       "           ... \n",
       "0.000320      1\n",
       "0.000182      1\n",
       "0.464500      1\n",
       "0.464500      1\n",
       "0.464499      1\n",
       "Name: count, Length: 662, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4_divergences = divergences[divergences[\"model_name\"] == \"openai-gpt-4\"]\n",
    "gpt4_divergences.js_dist.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa7bd341-b810-4a3f-b730-f8186936d5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0m/231b9j890r542zfr6djkqlz40000gp/T/ipykernel_42770/4163965735.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ).groupby(['model_name'], as_index=False, sort=False).apply(lambda x: x.loc[x[\"Mean\"].idxmax(), :])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>Agr. w/ Neg.</td>\n",
       "      <td>0.239636</td>\n",
       "      <td>0.033910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>N/Y</td>\n",
       "      <td>0.256461</td>\n",
       "      <td>0.032199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>Agr. w/ Neg.</td>\n",
       "      <td>0.190244</td>\n",
       "      <td>0.056740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.295296</td>\n",
       "      <td>0.048751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.113800</td>\n",
       "      <td>0.054546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.335724</td>\n",
       "      <td>0.027631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.3-70B-Instruct</td>\n",
       "      <td>Negation</td>\n",
       "      <td>0.335640</td>\n",
       "      <td>0.168559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>Disagr. w/ Neg.</td>\n",
       "      <td>0.166641</td>\n",
       "      <td>0.019487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OLMo-2-1124-7B</td>\n",
       "      <td>Disagr. w/ Neg.</td>\n",
       "      <td>0.373452</td>\n",
       "      <td>0.049581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OLMo-2-1124-7B-Instruct</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.533304</td>\n",
       "      <td>0.115831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>Options</td>\n",
       "      <td>0.292179</td>\n",
       "      <td>0.023216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.200194</td>\n",
       "      <td>0.046458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gemma-7b-it</td>\n",
       "      <td>N/Y</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai-gpt-4</td>\n",
       "      <td>N/Y</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model          Variant      Mean       Std\n",
       "0                 Llama-3.2-1B     Agr. w/ Neg.  0.239636  0.033910\n",
       "1        Llama-3.2-1B-Instruct              N/Y  0.256461  0.032199\n",
       "2                 Llama-3.2-3B     Agr. w/ Neg.  0.190244  0.056740\n",
       "3        Llama-3.2-3B-Instruct       Options F.  0.295296  0.048751\n",
       "4                 Llama-3.1-8B       Options F.  0.113800  0.054546\n",
       "5        Llama-3.1-8B-Instruct       Options F.  0.335724  0.027631\n",
       "6       Llama-3.3-70B-Instruct         Negation  0.335640  0.168559\n",
       "7                  gpt2-medium  Disagr. w/ Neg.  0.166641  0.019487\n",
       "8               OLMo-2-1124-7B  Disagr. w/ Neg.  0.373452  0.049581\n",
       "9      OLMo-2-1124-7B-Instruct       Options F.  0.533304  0.115831\n",
       "10  Ministral-8B-Instruct-2410          Options  0.292179  0.023216\n",
       "11                    gemma-7b       Options F.  0.200194  0.046458\n",
       "12                 gemma-7b-it              N/Y       inf       NaN\n",
       "13                openai-gpt-4              N/Y       inf       NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance_variant_for_model = divergences.groupby(['model_name', 'prompt_type'], as_index=False, sort=False).aggregate(\n",
    "    Mean = pd.NamedAgg('js_dist', \"mean\"),\n",
    "    Std = pd.NamedAgg('js_dist', \"std\")\n",
    ").groupby(['model_name'], as_index=False, sort=False).apply(lambda x: x.loc[x[\"Mean\"].idxmax(), :])\n",
    "max_distance_variant_for_model = max_distance_variant_for_model.rename({'model_name' : 'Model', 'prompt_type': 'Variant'}, axis=1)\n",
    "max_distance_variant_for_model = max_distance_variant_for_model.replace(\n",
    "    {\n",
    "        \"agreement_negation\": \"Agr. w/ Neg.\", \n",
    "        \"no_or_yes\": \"N/Y\", \n",
    "        \"disagreement_negation\": \"Disagr. w/ Neg.\", \n",
    "        \"options_flipped\": \"Options F.\", \n",
    "        \"options\": \"Options\", \n",
    "        \"negation\": \"Negation\",\n",
    "    }\n",
    ")\n",
    "max_distance_variant_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bec5763-167a-4b6d-aede-5765ee924577",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance_variant_for_model.to_latex(\"reports/robustness-prompt-type-distance.tex\", float_format=\"%0.2f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc81fb7-90f5-49bc-aae8-0b52271992bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prej-prompt",
   "language": "python",
   "name": "prej-prompt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
