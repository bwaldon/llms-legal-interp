{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f686275-e737-48cb-8418-0517544d80b6",
   "metadata": {},
   "source": [
    "# Analysis of Model judgments for robustness to question variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6bac8a-b54e-4977-a2be-621ee695953f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekp/miniconda3/envs/prej_prompt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import output_processing as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9401804b-721b-48f4-8f82-57e88d0337dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    # Main set of models with instruct divide and size variety\n",
    "    \"meta-llama/Llama-3.2-1B\",\n",
    "    \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    \"meta-llama/Llama-3.2-3B\",\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    \"meta-llama/Llama-3.1-8B\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    # Small reference model - would allow for pretraining variation\n",
    "    \"gpt2-medium\",\n",
    "    # Other open models\n",
    "    \"allenai/OLMo-2-1124-7B\",\n",
    "    \"allenai/OLMo-2-1124-7B-Instruct\",\n",
    "    \"mistralai/Ministral-8B-Instruct-2410\",\n",
    "    \"google/gemma-7b\",\n",
    "    \"google/gemma-7b-it\",\n",
    "    # Large platform model\n",
    "    \"openai-gpt-4\",\n",
    "]\n",
    "\n",
    "def read_and_organize_model_results(model_name):\n",
    "    model_results = pd.read_csv(f\"runs/results_09_29/{model_name}-results.csv\")\n",
    "    model_results.replace([0.0], -65504, inplace=True)\n",
    "    model_results = op.organize_distribution(model_results)\n",
    "    model_results[\"model_name\"] = model_name.split(\"/\")[-1]\n",
    "    model_results.loc[model_results[\"Covered\"] == True, \"Judgment\"] = \"Covered\"\n",
    "    model_results.loc[model_results[\"Covered\"] == True, \"Judgment_prob\"] = model_results[\"Covered_prob\"]\n",
    "    model_results.loc[model_results[\"NotCovered\"] == True, \"Judgment\"] = \"NotCovered\"\n",
    "    model_results.loc[model_results[\"NotCovered\"] == True, \"Judgment_prob\"] = model_results[\"NotCovered_prob\"]\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0d8896-23da-461a-a999-841429dc9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16146, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO organize the output for better clarity\n",
    "combined_results = [read_and_organize_model_results(model_name) for model_name in model_list]\n",
    "combined_df = pd.concat(combined_results).reset_index()\n",
    "combined_df.loc[:, \"item\"] = combined_df[\"title\"] + combined_df[\"version\"]\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b8e0dd0-ef6d-4d48-a568-6a2dabe43d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Llama-3.2-1B' 'Llama-3.2-1B-Instruct' 'Llama-3.2-3B'\n",
      " 'Llama-3.2-3B-Instruct' 'Llama-3.1-8B' 'Llama-3.1-8B-Instruct'\n",
      " 'gpt2-medium' 'OLMo-2-1124-7B' 'OLMo-2-1124-7B-Instruct'\n",
      " 'Ministral-8B-Instruct-2410' 'gemma-7b' 'gemma-7b-it' 'openai-gpt-4']\n"
     ]
    }
   ],
   "source": [
    "# Print summary of the experimental results\n",
    "print(combined_df.model_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f361805c-16d9-41dd-9072-b5964dfd6b68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>version</th>\n",
       "      <th>output</th>\n",
       "      <th>output_text</th>\n",
       "      <th>cum_logprob</th>\n",
       "      <th>YES_probs</th>\n",
       "      <th>Yes_probs</th>\n",
       "      <th>...</th>\n",
       "      <th>UnAff_prob</th>\n",
       "      <th>Covered_prob</th>\n",
       "      <th>NotCovered_prob</th>\n",
       "      <th>Covered</th>\n",
       "      <th>NotCovered</th>\n",
       "      <th>entropy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>Judgment</th>\n",
       "      <th>Judgment_prob</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15112</th>\n",
       "      <td>208</td>\n",
       "      <td>Personal Accident I</td>\n",
       "      <td>no_or_yes</td>\n",
       "      <td>Gwen's car insurance policy includes coverage ...</td>\n",
       "      <td>unambiguous_covered</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.260053</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>1.670954e-08</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.670954e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>openai-gpt-4</td>\n",
       "      <td>Covered</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>Personal Accident Iunambiguous_covered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                title prompt_type  \\\n",
       "15112    208  Personal Accident I   no_or_yes   \n",
       "\n",
       "                                                  prompt              version  \\\n",
       "15112  Gwen's car insurance policy includes coverage ...  unambiguous_covered   \n",
       "\n",
       "      output output_text  cum_logprob  YES_probs  Yes_probs  ...  \\\n",
       "15112    Yes         Yes          NaN -15.260053   0.000043  ...   \n",
       "\n",
       "         UnAff_prob  Covered_prob  NotCovered_prob  Covered  NotCovered  \\\n",
       "15112  1.670954e-08      0.000043     1.670954e-08     True       False   \n",
       "\n",
       "        entropy    model_name  Judgment  Judgment_prob  \\\n",
       "15112  0.000476  openai-gpt-4   Covered       0.000043   \n",
       "\n",
       "                                         item  \n",
       "15112  Personal Accident Iunambiguous_covered  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at one of the result samples\n",
    "combined_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb6b33-e77b-4368-bba5-895f0405bcec",
   "metadata": {},
   "source": [
    "## Prepare the table with Categorical counts and Distributional Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbf877e-1aa7-4249-8e15-aecae113db7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Covered</th>\n",
       "      <th>NotCovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>51</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>75</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OLMo-2-1124-7B</td>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OLMo-2-1124-7B-Instruct</td>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>48</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gemma-7b-it</td>\n",
       "      <td>131</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>openai-gpt-4</td>\n",
       "      <td>52</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Covered  NotCovered\n",
       "0                 Llama-3.2-1B      138           0\n",
       "1        Llama-3.2-1B-Instruct      138           0\n",
       "2                 Llama-3.2-3B      129           9\n",
       "3        Llama-3.2-3B-Instruct       51          87\n",
       "4                 Llama-3.1-8B       75          63\n",
       "5        Llama-3.1-8B-Instruct        0         138\n",
       "6                  gpt2-medium        5         133\n",
       "7               OLMo-2-1124-7B       73          65\n",
       "8      OLMo-2-1124-7B-Instruct       53          85\n",
       "9   Ministral-8B-Instruct-2410       87          51\n",
       "10                    gemma-7b       48          90\n",
       "11                 gemma-7b-it      131           7\n",
       "12                openai-gpt-4       52          86"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical Counts for Yes/No question variant\n",
    "question_variant_mask = combined_df[\"prompt_type\"] == \"yes_or_no\"\n",
    "yes_or_no_df = combined_df[question_variant_mask]\n",
    "count_labels = yes_or_no_df.groupby('model_name', as_index=False, sort=False).aggregate(\n",
    "    {\n",
    "        'Covered': 'sum',\n",
    "        'NotCovered': 'sum',\n",
    "    }\n",
    ")\n",
    "count_labels = count_labels.rename({'model_name' : 'Model'}, axis=1)\n",
    "count_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fb6a52-8faa-4fb8-9e94-a01fa78aedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latex table just for categorical counts\n",
    "count_labels.to_latex(\"reports/yes_or_no_categorical_counts.tex\", index=True, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe0f958-b2cb-43bc-975d-110edd4e7c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OLMo-2-1124-7B</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OLMo-2-1124-7B-Instruct</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gemma-7b-it</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>openai-gpt-4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model   Min   Max\n",
       "0                 Llama-3.1-8B  0.12  0.34\n",
       "1        Llama-3.1-8B-Instruct  0.09  0.70\n",
       "2                 Llama-3.2-1B  0.06  0.27\n",
       "3        Llama-3.2-1B-Instruct  0.13  0.50\n",
       "4                 Llama-3.2-3B  0.08  0.50\n",
       "5        Llama-3.2-3B-Instruct  0.15  0.65\n",
       "6   Ministral-8B-Instruct-2410  0.20  0.58\n",
       "7               OLMo-2-1124-7B  0.18  0.56\n",
       "8      OLMo-2-1124-7B-Instruct  0.00  0.99\n",
       "9                     gemma-7b  0.17  0.43\n",
       "10                 gemma-7b-it  0.00  0.99\n",
       "11                 gpt2-medium  0.12  0.30\n",
       "12                openai-gpt-4  0.00  0.47"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distributional spread for Yes/No question variant\n",
    "question_variant_mask = combined_df[\"prompt_type\"] == \"yes_or_no\"\n",
    "yes_or_no_df = combined_df[question_variant_mask]\n",
    "\n",
    "# Util function\n",
    "yes_or_no_judgement_range = yes_or_no_df[['model_name', 'Covered_prob', 'NotCovered_prob']].melt(id_vars='model_name', value_vars=['Covered_prob', 'NotCovered_prob']).groupby('model_name', as_index=False).agg(\n",
    "    Min = pd.NamedAgg('value', lambda x: np.round(np.min(x), 2)),\n",
    "    Max = pd.NamedAgg('value', lambda x: np.round(np.max(x), 2)),\n",
    "    ).rename({\"model_name\": \"Model\"}, axis=1)\n",
    "\n",
    "yes_or_no_judgement_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14453bca-0415-4def-9514-86382dc64fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate latex table for yes_or_no judgement range\n",
    "yes_or_no_judgement_range.to_latex(\"reports/yes_or_no_distributional_spread.tex\", index=True, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffcd39d-7723-4757-aabd-3f9ae1d5908a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Covered</th>\n",
       "      <th>NotCovered</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B</th>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B</th>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>51</td>\n",
       "      <td>87</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>75</td>\n",
       "      <td>63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B</th>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B-Instruct</th>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ministral-8B-Instruct-2410</th>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>48</td>\n",
       "      <td>90</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>131</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt-4</th>\n",
       "      <td>52</td>\n",
       "      <td>86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Covered  NotCovered   Min   Max\n",
       "Model                                                      \n",
       "Llama-3.2-1B                    138           0  0.06  0.27\n",
       "Llama-3.2-1B-Instruct           138           0  0.13  0.50\n",
       "Llama-3.2-3B                    129           9  0.08  0.50\n",
       "Llama-3.2-3B-Instruct            51          87  0.15  0.65\n",
       "Llama-3.1-8B                     75          63  0.12  0.34\n",
       "Llama-3.1-8B-Instruct             0         138  0.09  0.70\n",
       "gpt2-medium                       5         133  0.12  0.30\n",
       "OLMo-2-1124-7B                   73          65  0.18  0.56\n",
       "OLMo-2-1124-7B-Instruct          53          85  0.00  0.99\n",
       "Ministral-8B-Instruct-2410       87          51  0.20  0.58\n",
       "gemma-7b                         48          90  0.17  0.43\n",
       "gemma-7b-it                     131           7  0.00  0.99\n",
       "openai-gpt-4                     52          86  0.00  0.47"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combined table\n",
    "# Merge the two tables\n",
    "yes_or_no_table = pd.concat([count_labels.set_index('Model'), yes_or_no_judgement_range.set_index('Model')], axis=1, join='inner')\n",
    "yes_or_no_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccda140a-06e8-440b-ae9a-29cc00496c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_or_no_table.to_latex(\"reports/yes_or_no_table.tex\", index=True, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023c2942-6326-46c2-af17-68b6dcb59f2f",
   "metadata": {},
   "source": [
    "## Prepare the majority votes frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c13f17-e30e-4e67-9a0a-4a1da450c777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Majority Count</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>8.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B</th>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>129.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B</th>\n",
       "      <td>79.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>77.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ministral-8B-Instruct-2410</th>\n",
       "      <td>20.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B</th>\n",
       "      <td>47.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B-Instruct</th>\n",
       "      <td>51.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>44.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>50.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt-4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Frequency                       \n",
       "Majority Count                     5     6     7     8    9\n",
       "Model                                                      \n",
       "Llama-3.1-8B                    40.0  50.0  48.0   0.0  0.0\n",
       "Llama-3.1-8B-Instruct            8.0  41.0  56.0  29.0  4.0\n",
       "Llama-3.2-1B                    10.0  59.0  69.0   0.0  0.0\n",
       "Llama-3.2-1B-Instruct          129.0   9.0   0.0   0.0  0.0\n",
       "Llama-3.2-3B                    79.0  55.0   4.0   0.0  0.0\n",
       "Llama-3.2-3B-Instruct           77.0  46.0  15.0   0.0  0.0\n",
       "Ministral-8B-Instruct-2410      20.0  67.0  26.0  24.0  1.0\n",
       "OLMo-2-1124-7B                  47.0  64.0  20.0   7.0  0.0\n",
       "OLMo-2-1124-7B-Instruct         51.0  57.0  30.0   0.0  0.0\n",
       "gemma-7b                        44.0  60.0  29.0   5.0  0.0\n",
       "gemma-7b-it                     10.0  33.0  79.0  16.0  0.0\n",
       "gpt2-medium                     50.0  83.0   5.0   0.0  0.0\n",
       "openai-gpt-4                    61.0  45.0  27.0   5.0  0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the majority votes\n",
    "majority_vote_by_model = combined_df.groupby(['title', 'version', 'model_name'], as_index=False, sort=False).aggregate(\n",
    "     {\n",
    "        'Covered': 'sum',\n",
    "        'NotCovered': 'sum',\n",
    "    }\n",
    ")\n",
    "majority_vote_by_model.loc[:, \"majority_count\"] = majority_vote_by_model[['Covered', 'NotCovered']].max(axis=1)\n",
    "majority_vote_by_model.shape\n",
    "majority_vote_table_df = majority_vote_by_model[[\"model_name\", \"majority_count\"]].value_counts().reset_index(name=\"Frequency\")\\\n",
    ".pivot_table(columns =['majority_count'], index=\"model_name\", aggfunc=\"sum\", margins=True)\\\n",
    "\n",
    "majority_vote_table_df.replace(np.nan, 0, inplace=True)\n",
    "# Remove the \"All\" from columns and rows\n",
    "majority_vote_table_df = majority_vote_table_df.drop([\"All\"], axis=0)\n",
    "majority_vote_table_df = majority_vote_table_df.drop([(\"Frequency\", \"All\")], axis=1)\n",
    "\n",
    "majority_vote_table_df = majority_vote_table_df.rename({'model_name': 'Model', 'majority_count': 'Majority Count'})\n",
    "majority_vote_table_df.index = majority_vote_table_df.index.rename('Model')\n",
    "majority_vote_table_df.columns.names = [None, 'Majority Count']\n",
    "majority_vote_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f15ef0da-baba-4922-b689-2c51b60bfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_vote_table_df.to_latex(\"reports/majority-votes-freq-table.tex\", float_format=\"%.0f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbebf0-3e67-4fe3-983d-0fb3f2144b28",
   "metadata": {},
   "source": [
    "## Make the table for Jensen-Shannon Distance for non Yes/No question variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd7996cc-aec9-47bb-b237-dae63b97eaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>version</th>\n",
       "      <th>model_name</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>js_dist</th>\n",
       "      <th>kl_div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4669</th>\n",
       "      <td>Garden Plants I</td>\n",
       "      <td>unambiguous_covered</td>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>disagreement_negation</td>\n",
       "      <td>0.062089</td>\n",
       "      <td>0.015705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                title              version    model_name  \\\n",
       "4669  Garden Plants I  unambiguous_covered  Llama-3.1-8B   \n",
       "\n",
       "                prompt_type   js_dist    kl_div  \n",
       "4669  disagreement_negation  0.062089  0.015705  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divergences = op.calculate_relative_measures(combined_df)\n",
    "divergences.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7bd341-b810-4a3f-b730-f8186936d5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0m/231b9j890r542zfr6djkqlz40000gp/T/ipykernel_85609/4163965735.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ).groupby(['model_name'], as_index=False, sort=False).apply(lambda x: x.loc[x[\"Mean\"].idxmax(), :])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>Agr. w/ Neg.</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.033502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>N/Y</td>\n",
       "      <td>0.244847</td>\n",
       "      <td>0.031106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>Agr. w/ Neg.</td>\n",
       "      <td>0.185209</td>\n",
       "      <td>0.055686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.260064</td>\n",
       "      <td>0.050909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.095668</td>\n",
       "      <td>0.051488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.277773</td>\n",
       "      <td>0.027844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>Disagr. w/ Neg.</td>\n",
       "      <td>0.166143</td>\n",
       "      <td>0.019285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OLMo-2-1124-7B</td>\n",
       "      <td>Disagr. w/ Neg.</td>\n",
       "      <td>0.382940</td>\n",
       "      <td>0.052281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OLMo-2-1124-7B-Instruct</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.532485</td>\n",
       "      <td>0.115830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>Options</td>\n",
       "      <td>0.250857</td>\n",
       "      <td>0.026262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.134082</td>\n",
       "      <td>0.041130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gemma-7b-it</td>\n",
       "      <td>Options</td>\n",
       "      <td>0.762098</td>\n",
       "      <td>0.036062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>openai-gpt-4</td>\n",
       "      <td>Negation</td>\n",
       "      <td>0.169361</td>\n",
       "      <td>0.152490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model          Variant      Mean       Std\n",
       "0                 Llama-3.2-1B     Agr. w/ Neg.  0.234301  0.033502\n",
       "1        Llama-3.2-1B-Instruct              N/Y  0.244847  0.031106\n",
       "2                 Llama-3.2-3B     Agr. w/ Neg.  0.185209  0.055686\n",
       "3        Llama-3.2-3B-Instruct       Options F.  0.260064  0.050909\n",
       "4                 Llama-3.1-8B       Options F.  0.095668  0.051488\n",
       "5        Llama-3.1-8B-Instruct       Options F.  0.277773  0.027844\n",
       "6                  gpt2-medium  Disagr. w/ Neg.  0.166143  0.019285\n",
       "7               OLMo-2-1124-7B  Disagr. w/ Neg.  0.382940  0.052281\n",
       "8      OLMo-2-1124-7B-Instruct       Options F.  0.532485  0.115830\n",
       "9   Ministral-8B-Instruct-2410          Options  0.250857  0.026262\n",
       "10                    gemma-7b       Options F.  0.134082  0.041130\n",
       "11                 gemma-7b-it          Options  0.762098  0.036062\n",
       "12                openai-gpt-4         Negation  0.169361  0.152490"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance_variant_for_model = divergences.groupby(['model_name', 'prompt_type'], as_index=False, sort=False).aggregate(\n",
    "    Mean = pd.NamedAgg('js_dist', \"mean\"),\n",
    "    Std = pd.NamedAgg('js_dist', \"std\")\n",
    ").groupby(['model_name'], as_index=False, sort=False).apply(lambda x: x.loc[x[\"Mean\"].idxmax(), :])\n",
    "max_distance_variant_for_model = max_distance_variant_for_model.rename({'model_name' : 'Model', 'prompt_type': 'Variant'}, axis=1)\n",
    "max_distance_variant_for_model = max_distance_variant_for_model.replace(\n",
    "    {\n",
    "        \"agreement_negation\": \"Agr. w/ Neg.\", \n",
    "        \"no_or_yes\": \"N/Y\", \n",
    "        \"disagreement_negation\": \"Disagr. w/ Neg.\", \n",
    "        \"options_flipped\": \"Options F.\", \n",
    "        \"options\": \"Options\", \n",
    "        \"negation\": \"Negation\",\n",
    "    }\n",
    ")\n",
    "max_distance_variant_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bec5763-167a-4b6d-aede-5765ee924577",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance_variant_for_model.to_latex(\"reports/robustness-prompt-type-distance.tex\", float_format=\"%0.2f\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prej-prompt",
   "language": "python",
   "name": "prej-prompt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
