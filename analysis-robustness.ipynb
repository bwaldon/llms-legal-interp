{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f686275-e737-48cb-8418-0517544d80b6",
   "metadata": {},
   "source": [
    "# Analysis of Model judgments for robustness to question variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6bac8a-b54e-4977-a2be-621ee695953f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekp/miniconda3/envs/prej_prompt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import output_processing as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9401804b-721b-48f4-8f82-57e88d0337dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    # Main set of models with instruct divide and size variety\n",
    "    \"meta-llama/Llama-3.2-1B\",\n",
    "    \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    \"meta-llama/Llama-3.2-3B\",\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    \"meta-llama/Llama-3.1-8B\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    # Small reference model - would allow for pretraining variation\n",
    "    \"gpt2-medium\",\n",
    "    # Other open models\n",
    "    \"allenai/OLMo-2-1124-7B\",\n",
    "    \"allenai/OLMo-2-1124-7B-Instruct\",\n",
    "    \"mistralai/Ministral-8B-Instruct-2410\",\n",
    "    \"google/gemma-7b\",\n",
    "    \"google/gemma-7b-it\",\n",
    "    # Large platform model\n",
    "    \"openai-gpt-4\",\n",
    "]\n",
    "\n",
    "def read_and_organize_model_results(model_name):\n",
    "    model_results = pd.read_csv(f\"runs/runs-42_07_16/{model_name}-results.csv\")\n",
    "    model_results.replace([0.0], -65504, inplace=True)\n",
    "    model_results = op.organize_distribution(model_results)\n",
    "    model_results[\"model_name\"] = model_name.split(\"/\")[-1]\n",
    "    model_results.loc[model_results[\"Covered\"] == True, \"Judgment\"] = \"Covered\"\n",
    "    model_results.loc[model_results[\"Covered\"] == True, \"Judgment_prob\"] = model_results[\"Covered_prob\"]\n",
    "    model_results.loc[model_results[\"NotCovered\"] == True, \"Judgment\"] = \"NotCovered\"\n",
    "    model_results.loc[model_results[\"NotCovered\"] == True, \"Judgment_prob\"] = model_results[\"NotCovered_prob\"]\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0d8896-23da-461a-a999-841429dc9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO organize the output for better clarity\n",
    "combined_results = [read_and_organize_model_results(model_name) for model_name in model_list]\n",
    "combined_df = pd.concat(combined_results).reset_index()\n",
    "combined_df.loc[:, \"item\"] = combined_df[\"title\"] + combined_df[\"version\"]\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b8e0dd0-ef6d-4d48-a568-6a2dabe43d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Llama-3.2-1B' 'Llama-3.2-1B-Instruct' 'Llama-3.2-3B'\n",
      " 'Llama-3.2-3B-Instruct' 'Llama-3.1-8B' 'Llama-3.1-8B-Instruct'\n",
      " 'Llama-3.3-70B-Instruct' 'gpt2-medium' 'OLMo-2-1124-7B'\n",
      " 'OLMo-2-1124-7B-Instruct' 'Ministral-8B-Instruct-2410' 'gemma-7b'\n",
      " 'gemma-7b-it' 'openai-gpt-4']\n"
     ]
    }
   ],
   "source": [
    "# Print summary of the experimental results\n",
    "print(combined_df.model_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f361805c-16d9-41dd-9072-b5964dfd6b68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>version</th>\n",
       "      <th>output</th>\n",
       "      <th>output_text</th>\n",
       "      <th>cum_logprob</th>\n",
       "      <th>YES_probs</th>\n",
       "      <th>Yes_probs</th>\n",
       "      <th>...</th>\n",
       "      <th>UnAff_prob</th>\n",
       "      <th>Covered_prob</th>\n",
       "      <th>NotCovered_prob</th>\n",
       "      <th>Covered</th>\n",
       "      <th>NotCovered</th>\n",
       "      <th>entropy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>Judgment</th>\n",
       "      <th>Judgment_prob</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14640</th>\n",
       "      <td>978</td>\n",
       "      <td>Escape of Water I</td>\n",
       "      <td>options</td>\n",
       "      <td>Carol's home insurance policy includes coverag...</td>\n",
       "      <td>unambiguous_uncovered</td>\n",
       "      <td>B</td>\n",
       "      <td>B. Carol is not covered.\\nExplanation:\\nThe p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.326406</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300771</td>\n",
       "      <td>0.249348</td>\n",
       "      <td>0.300771</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.895992</td>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>NotCovered</td>\n",
       "      <td>0.300771</td>\n",
       "      <td>Escape of Water Iunambiguous_uncovered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index              title prompt_type  \\\n",
       "14640    978  Escape of Water I     options   \n",
       "\n",
       "                                                  prompt  \\\n",
       "14640  Carol's home insurance policy includes coverag...   \n",
       "\n",
       "                     version output  \\\n",
       "14640  unambiguous_uncovered      B   \n",
       "\n",
       "                                             output_text  cum_logprob  \\\n",
       "14640   B. Carol is not covered.\\nExplanation:\\nThe p...          NaN   \n",
       "\n",
       "       YES_probs  Yes_probs  ...  UnAff_prob  Covered_prob  NotCovered_prob  \\\n",
       "14640  -9.326406   0.001241  ...    0.300771      0.249348         0.300771   \n",
       "\n",
       "       Covered  NotCovered   entropy  model_name    Judgment  Judgment_prob  \\\n",
       "14640    False        True  0.895992    gemma-7b  NotCovered       0.300771   \n",
       "\n",
       "                                         item  \n",
       "14640  Escape of Water Iunambiguous_uncovered  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at one of the result samples\n",
    "combined_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb6b33-e77b-4368-bba5-895f0405bcec",
   "metadata": {},
   "source": [
    "## Prepare the table with Categorical counts and Distributional Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbf877e-1aa7-4249-8e15-aecae113db7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Covered</th>\n",
       "      <th>NotCovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>51</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>75</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.3-70B-Instruct</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OLMo-2-1124-7B</td>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OLMo-2-1124-7B-Instruct</td>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>48</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gemma-7b-it</td>\n",
       "      <td>131</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai-gpt-4</td>\n",
       "      <td>52</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Covered  NotCovered\n",
       "0                 Llama-3.2-1B      138           0\n",
       "1        Llama-3.2-1B-Instruct      138           0\n",
       "2                 Llama-3.2-3B      129           9\n",
       "3        Llama-3.2-3B-Instruct       51          87\n",
       "4                 Llama-3.1-8B       75          63\n",
       "5        Llama-3.1-8B-Instruct        0         138\n",
       "6       Llama-3.3-70B-Instruct       59          79\n",
       "7                  gpt2-medium        5         133\n",
       "8               OLMo-2-1124-7B       73          65\n",
       "9      OLMo-2-1124-7B-Instruct       53          85\n",
       "10  Ministral-8B-Instruct-2410       87          51\n",
       "11                    gemma-7b       48          90\n",
       "12                 gemma-7b-it      131           7\n",
       "13                openai-gpt-4       52          86"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical Counts for Yes/No question variant\n",
    "question_variant_mask = combined_df[\"prompt_type\"] == \"yes_or_no\"\n",
    "yes_or_no_df = combined_df[question_variant_mask]\n",
    "count_labels = yes_or_no_df.groupby('model_name', as_index=False, sort=False).aggregate(\n",
    "    {\n",
    "        'Covered': 'sum',\n",
    "        'NotCovered': 'sum',\n",
    "    }\n",
    ")\n",
    "count_labels = count_labels.rename({'model_name' : 'Model'}, axis=1)\n",
    "count_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fb6a52-8faa-4fb8-9e94-a01fa78aedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latex table just for categorical counts\n",
    "count_labels.to_latex(\"reports/yes_or_no_categorical_counts.tex\", index=True, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe0f958-b2cb-43bc-975d-110edd4e7c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.3-70B-Instruct</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OLMo-2-1124-7B</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OLMo-2-1124-7B-Instruct</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gemma-7b-it</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai-gpt-4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model   Min   Max\n",
       "0                 Llama-3.1-8B  0.12  0.34\n",
       "1        Llama-3.1-8B-Instruct  0.09  0.70\n",
       "2                 Llama-3.2-1B  0.06  0.27\n",
       "3        Llama-3.2-1B-Instruct  0.13  0.50\n",
       "4                 Llama-3.2-3B  0.08  0.50\n",
       "5        Llama-3.2-3B-Instruct  0.15  0.65\n",
       "6       Llama-3.3-70B-Instruct  0.02  0.81\n",
       "7   Ministral-8B-Instruct-2410  0.20  0.58\n",
       "8               OLMo-2-1124-7B  0.18  0.56\n",
       "9      OLMo-2-1124-7B-Instruct  0.00  0.99\n",
       "10                    gemma-7b  0.17  0.43\n",
       "11                 gemma-7b-it  0.00  0.99\n",
       "12                 gpt2-medium  0.12  0.30\n",
       "13                openai-gpt-4  0.00  0.47"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distributional spread for Yes/No question variant\n",
    "question_variant_mask = combined_df[\"prompt_type\"] == \"yes_or_no\"\n",
    "yes_or_no_df = combined_df[question_variant_mask]\n",
    "\n",
    "# Util function\n",
    "yes_or_no_judgement_range = yes_or_no_df[['model_name', 'Covered_prob', 'NotCovered_prob']].melt(id_vars='model_name', value_vars=['Covered_prob', 'NotCovered_prob']).groupby('model_name', as_index=False).agg(\n",
    "    Min = pd.NamedAgg('value', lambda x: np.round(np.min(x), 2)),\n",
    "    Max = pd.NamedAgg('value', lambda x: np.round(np.max(x), 2)),\n",
    "    ).rename({\"model_name\": \"Model\"}, axis=1)\n",
    "\n",
    "yes_or_no_judgement_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14453bca-0415-4def-9514-86382dc64fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate latex table for yes_or_no judgement range\n",
    "yes_or_no_judgement_range.to_latex(\"reports/yes_or_no_distributional_spread.tex\", index=True, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffcd39d-7723-4757-aabd-3f9ae1d5908a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Covered</th>\n",
       "      <th>NotCovered</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B</th>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B</th>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>51</td>\n",
       "      <td>87</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>75</td>\n",
       "      <td>63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.3-70B-Instruct</th>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B</th>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B-Instruct</th>\n",
       "      <td>53</td>\n",
       "      <td>85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ministral-8B-Instruct-2410</th>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>48</td>\n",
       "      <td>90</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>131</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt-4</th>\n",
       "      <td>52</td>\n",
       "      <td>86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Covered  NotCovered   Min   Max\n",
       "Model                                                      \n",
       "Llama-3.2-1B                    138           0  0.06  0.27\n",
       "Llama-3.2-1B-Instruct           138           0  0.13  0.50\n",
       "Llama-3.2-3B                    129           9  0.08  0.50\n",
       "Llama-3.2-3B-Instruct            51          87  0.15  0.65\n",
       "Llama-3.1-8B                     75          63  0.12  0.34\n",
       "Llama-3.1-8B-Instruct             0         138  0.09  0.70\n",
       "Llama-3.3-70B-Instruct           59          79  0.02  0.81\n",
       "gpt2-medium                       5         133  0.12  0.30\n",
       "OLMo-2-1124-7B                   73          65  0.18  0.56\n",
       "OLMo-2-1124-7B-Instruct          53          85  0.00  0.99\n",
       "Ministral-8B-Instruct-2410       87          51  0.20  0.58\n",
       "gemma-7b                         48          90  0.17  0.43\n",
       "gemma-7b-it                     131           7  0.00  0.99\n",
       "openai-gpt-4                     52          86  0.00  0.47"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combined table\n",
    "# Merge the two tables\n",
    "yes_or_no_table = pd.concat([count_labels.set_index('Model'), yes_or_no_judgement_range.set_index('Model')], axis=1, join='inner')\n",
    "yes_or_no_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccda140a-06e8-440b-ae9a-29cc00496c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_or_no_table.to_latex(\"reports/yes_or_no_table.tex\", index=True, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023c2942-6326-46c2-af17-68b6dcb59f2f",
   "metadata": {},
   "source": [
    "## Prepare the majority votes frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c13f17-e30e-4e67-9a0a-4a1da450c777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Majority Count</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>8.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B</th>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>129.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B</th>\n",
       "      <td>79.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>77.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.3-70B-Instruct</th>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ministral-8B-Instruct-2410</th>\n",
       "      <td>20.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B</th>\n",
       "      <td>47.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B-Instruct</th>\n",
       "      <td>51.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>44.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>50.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt-4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Frequency                       \n",
       "Majority Count                     5     6     7     8    9\n",
       "Model                                                      \n",
       "Llama-3.1-8B                    40.0  50.0  48.0   0.0  0.0\n",
       "Llama-3.1-8B-Instruct            8.0  41.0  56.0  29.0  4.0\n",
       "Llama-3.2-1B                    10.0  59.0  69.0   0.0  0.0\n",
       "Llama-3.2-1B-Instruct          129.0   9.0   0.0   0.0  0.0\n",
       "Llama-3.2-3B                    79.0  55.0   4.0   0.0  0.0\n",
       "Llama-3.2-3B-Instruct           77.0  46.0  15.0   0.0  0.0\n",
       "Llama-3.3-70B-Instruct          24.0  34.0  78.0   2.0  0.0\n",
       "Ministral-8B-Instruct-2410      20.0  67.0  26.0  24.0  1.0\n",
       "OLMo-2-1124-7B                  47.0  64.0  20.0   7.0  0.0\n",
       "OLMo-2-1124-7B-Instruct         51.0  57.0  30.0   0.0  0.0\n",
       "gemma-7b                        44.0  60.0  29.0   5.0  0.0\n",
       "gemma-7b-it                     10.0  33.0  79.0  16.0  0.0\n",
       "gpt2-medium                     50.0  83.0   5.0   0.0  0.0\n",
       "openai-gpt-4                    61.0  45.0  27.0   5.0  0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the majority votes\n",
    "majority_vote_by_model = combined_df.groupby(['title', 'version', 'model_name'], as_index=False, sort=False).aggregate(\n",
    "     {\n",
    "        'Covered': 'sum',\n",
    "        'NotCovered': 'sum',\n",
    "    }\n",
    ")\n",
    "majority_vote_by_model.loc[:, \"majority_count\"] = majority_vote_by_model[['Covered', 'NotCovered']].max(axis=1)\n",
    "majority_vote_by_model.shape\n",
    "majority_vote_table_df = majority_vote_by_model[[\"model_name\", \"majority_count\"]].value_counts().reset_index(name=\"Frequency\")\\\n",
    ".pivot_table(columns =['majority_count'], index=\"model_name\", aggfunc=\"sum\", margins=True)\\\n",
    "\n",
    "majority_vote_table_df.replace(np.nan, 0, inplace=True)\n",
    "# Remove the \"All\" from columns and rows\n",
    "majority_vote_table_df = majority_vote_table_df.drop([\"All\"], axis=0)\n",
    "majority_vote_table_df = majority_vote_table_df.drop([(\"Frequency\", \"All\")], axis=1)\n",
    "\n",
    "majority_vote_table_df = majority_vote_table_df.rename({'model_name': 'Model', 'majority_count': 'Majority Count'})\n",
    "majority_vote_table_df.index = majority_vote_table_df.index.rename('Model')\n",
    "majority_vote_table_df.columns.names = [None, 'Majority Count']\n",
    "majority_vote_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f15ef0da-baba-4922-b689-2c51b60bfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_vote_table_df.to_latex(\"reports/majority-votes-freq-table.tex\", float_format=\"%.0f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4ea87-1e71-42f9-a347-8f040ff0ac0f",
   "metadata": {},
   "source": [
    "## Minority responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0726f6a-f6f8-4daf-9e55-25cd1bd57764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 17388)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minority responses\n",
    "combined_df.loc[combined_df.Covered == True, \"judgment\"] = \"Covered\"\n",
    "combined_df.loc[combined_df.NotCovered == True, \"judgment\"] = \"Not Covered\"\n",
    "majority_vote_by_model.loc[:, \"majority\"] = majority_vote_by_model.apply(lambda x: \"Covered\" if x.Covered >= x.NotCovered else \"Not Covered\",  axis=1)\n",
    "combined_df.loc[:, \"in_minority\"]= False\n",
    "for index, row in majority_vote_by_model.iterrows():\n",
    "    item_model_mask = (combined_df[\"title\"] == row.title) & (combined_df[\"version\"] == row.version) & (combined_df[\"model_name\"] == row.model_name)\n",
    "    in_minority_mask = combined_df[\"judgment\"]!= row.majority\n",
    "    combined_df.loc[item_model_mask & in_minority_mask, \"in_minority\"] = True\n",
    "\n",
    "combined_df.in_minority.sum(), combined_df.shape[0]\n",
    "\n",
    "## Minority responses by question variants for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "927103bb-1794-4547-9837-b2a90deea2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_responses = combined_df[combined_df.in_minority == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed34c03-4dec-4b7a-9a32-42ba38b73edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"9\" halign=\"left\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_type</th>\n",
       "      <th>agreement</th>\n",
       "      <th>agreement_negation</th>\n",
       "      <th>disagreement</th>\n",
       "      <th>disagreement_negation</th>\n",
       "      <th>negation</th>\n",
       "      <th>no_or_yes</th>\n",
       "      <th>options</th>\n",
       "      <th>options_flipped</th>\n",
       "      <th>yes_or_no</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>21.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>12.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B</th>\n",
       "      <td>106.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>51.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.3-70B-Instruct</th>\n",
       "      <td>14.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ministral-8B-Instruct-2410</th>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B</th>\n",
       "      <td>62.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLMo-2-1124-7B-Instruct</th>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>22.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>125.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt-4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count                                  \\\n",
       "prompt_type                agreement agreement_negation disagreement   \n",
       "model_name                                                             \n",
       "Llama-3.1-8B                    21.0              101.0        110.0   \n",
       "Llama-3.1-8B-Instruct            5.0               33.0         58.0   \n",
       "Llama-3.2-1B                     0.0              138.0        138.0   \n",
       "Llama-3.2-1B-Instruct           12.0              126.0        126.0   \n",
       "Llama-3.2-3B                   106.0              138.0        108.0   \n",
       "Llama-3.2-3B-Instruct           51.0               70.0         70.0   \n",
       "Llama-3.3-70B-Instruct          14.0               57.0         46.0   \n",
       "Ministral-8B-Instruct-2410       8.0               52.0         80.0   \n",
       "OLMo-2-1124-7B                  62.0               57.0         67.0   \n",
       "OLMo-2-1124-7B-Instruct         34.0               68.0        106.0   \n",
       "gemma-7b                        22.0               63.0         95.0   \n",
       "gemma-7b-it                      8.0                5.0        127.0   \n",
       "gpt2-medium                    125.0               13.0         13.0   \n",
       "openai-gpt-4                    32.0               56.0         41.0   \n",
       "\n",
       "                                                                             \\\n",
       "prompt_type                disagreement_negation negation no_or_yes options   \n",
       "model_name                                                                    \n",
       "Llama-3.1-8B                                36.0     31.0      15.0    30.0   \n",
       "Llama-3.1-8B-Instruct                       75.0     33.0       1.0     1.0   \n",
       "Llama-3.2-1B                                 0.0      0.0      14.0    48.0   \n",
       "Llama-3.2-1B-Instruct                       12.0      0.0     126.0   117.0   \n",
       "Llama-3.2-3B                                 0.0      0.0       0.0   128.0   \n",
       "Llama-3.2-3B-Instruct                       68.0     40.0      32.0    61.0   \n",
       "Llama-3.3-70B-Instruct                      89.0     99.0      10.0    19.0   \n",
       "Ministral-8B-Instruct-2410                  59.0     51.0       5.0    80.0   \n",
       "OLMo-2-1124-7B                              67.0     29.0      27.0    46.0   \n",
       "OLMo-2-1124-7B-Instruct                     70.0     48.0       9.0    26.0   \n",
       "gemma-7b                                    47.0     30.0      14.0    71.0   \n",
       "gemma-7b-it                                104.0     26.0       5.0     5.0   \n",
       "gpt2-medium                                125.0     42.0       4.0    91.0   \n",
       "openai-gpt-4                                72.0     44.0      58.0    56.0   \n",
       "\n",
       "                                                      \n",
       "prompt_type                options_flipped yes_or_no  \n",
       "model_name                                            \n",
       "Llama-3.1-8B                          31.0      31.0  \n",
       "Llama-3.1-8B-Instruct                 89.0       1.0  \n",
       "Llama-3.2-1B                          17.0       0.0  \n",
       "Llama-3.2-1B-Instruct                 12.0      12.0  \n",
       "Llama-3.2-3B                           0.0       9.0  \n",
       "Llama-3.2-3B-Instruct                 61.0      23.0  \n",
       "Llama-3.3-70B-Instruct                18.0       4.0  \n",
       "Ministral-8B-Instruct-2410            17.0       5.0  \n",
       "OLMo-2-1124-7B                        60.0      12.0  \n",
       "OLMo-2-1124-7B-Instruct               57.0      17.0  \n",
       "gemma-7b                              34.0      43.0  \n",
       "gemma-7b-it                           31.0       2.0  \n",
       "gpt2-medium                           38.0       8.0  \n",
       "openai-gpt-4                          54.0      25.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_pivot = minority_responses[[\"model_name\", \"prompt_type\"]].value_counts().reset_index().pivot_table(index=\"model_name\", columns=\"prompt_type\")\n",
    "minority_pivot.replace(np.nan, 0, inplace=True)\n",
    "minority_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663bf788-ef3c-4983-b07a-d59c76414b73",
   "metadata": {},
   "source": [
    "## Minority responses by question variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df101ba8-176d-47d3-ba2d-d795e0beff25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 17388)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minority responses\n",
    "combined_df.loc[combined_df.Covered == True, \"judgment\"] = \"Covered\"\n",
    "combined_df.loc[combined_df.NotCovered == True, \"judgment\"] = \"Not Covered\"\n",
    "majority_vote_by_model.loc[:, \"majority\"] = majority_vote_by_model.apply(lambda x: \"Covered\" if x.Covered >= x.NotCovered else \"Not Covered\",  axis=1)\n",
    "combined_df.loc[:, \"in_minority\"]= False\n",
    "for index, row in majority_vote_by_model.iterrows():\n",
    "    item_model_mask = (combined_df[\"title\"] == row.title) & (combined_df[\"version\"] == row.version) & (combined_df[\"model_name\"] == row.model_name)\n",
    "    in_minority_mask = combined_df[\"judgment\"]!= row.majority\n",
    "    combined_df.loc[item_model_mask & in_minority_mask, \"in_minority\"] = True\n",
    "\n",
    "combined_df.in_minority.sum(), combined_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09dc0c33-a348-4cba-9de0-0e2868263dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disagreement</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agreement_negation</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disagreement_negation</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>options</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>options_flipped</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>agreement</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negation</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no_or_yes</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yes_or_no</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prompt_type  count\n",
       "0           disagreement   1185\n",
       "1     agreement_negation    977\n",
       "2  disagreement_negation    824\n",
       "3                options    779\n",
       "4        options_flipped    519\n",
       "5              agreement    500\n",
       "6               negation    473\n",
       "7              no_or_yes    320\n",
       "8              yes_or_no    192"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_responses = combined_df[combined_df.in_minority == True]\n",
    "minority_responses[[\"prompt_type\"]].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5d7043a-8825-4216-9b3d-1cf02b962c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disagreement</td>\n",
       "      <td>0.205408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agreement_negation</td>\n",
       "      <td>0.169353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disagreement_negation</td>\n",
       "      <td>0.142832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>options</td>\n",
       "      <td>0.135032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>options_flipped</td>\n",
       "      <td>0.089964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>agreement</td>\n",
       "      <td>0.086670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negation</td>\n",
       "      <td>0.081990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no_or_yes</td>\n",
       "      <td>0.055469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yes_or_no</td>\n",
       "      <td>0.033281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prompt_type     count\n",
       "0           disagreement  0.205408\n",
       "1     agreement_negation  0.169353\n",
       "2  disagreement_negation  0.142832\n",
       "3                options  0.135032\n",
       "4        options_flipped  0.089964\n",
       "5              agreement  0.086670\n",
       "6               negation  0.081990\n",
       "7              no_or_yes  0.055469\n",
       "8              yes_or_no  0.033281"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(minority_responses[[\"prompt_type\"]].value_counts()/minority_responses.shape[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a27ff17f-d7be-443d-aba5-9c6a1c5e776a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>disagreement</th>\n",
       "      <td>1185</td>\n",
       "      <td>0.205408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agreement_negation</th>\n",
       "      <td>977</td>\n",
       "      <td>0.169353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disagreement_negation</th>\n",
       "      <td>824</td>\n",
       "      <td>0.142832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>options</th>\n",
       "      <td>779</td>\n",
       "      <td>0.135032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>options_flipped</th>\n",
       "      <td>519</td>\n",
       "      <td>0.089964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agreement</th>\n",
       "      <td>500</td>\n",
       "      <td>0.086670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negation</th>\n",
       "      <td>473</td>\n",
       "      <td>0.081990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_or_yes</th>\n",
       "      <td>320</td>\n",
       "      <td>0.055469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes_or_no</th>\n",
       "      <td>192</td>\n",
       "      <td>0.033281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Count  Proportion\n",
       "prompt_type                             \n",
       "disagreement            1185    0.205408\n",
       "agreement_negation       977    0.169353\n",
       "disagreement_negation    824    0.142832\n",
       "options                  779    0.135032\n",
       "options_flipped          519    0.089964\n",
       "agreement                500    0.086670\n",
       "negation                 473    0.081990\n",
       "no_or_yes                320    0.055469\n",
       "yes_or_no                192    0.033281"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_counts = minority_responses[[\"prompt_type\"]].value_counts().reset_index().set_index(\"prompt_type\")\n",
    "minority_counts.columns = ['Count']\n",
    "minority_props = (minority_counts/minority_responses.shape[0]).reset_index().set_index(\"prompt_type\")\n",
    "minority_props.columns = ['Proportion']\n",
    "pd.concat([minority_counts, minority_props], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb46f342-1961-4f6c-855c-729b50377a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Count', 'Proportion'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([minority_counts, minority_props], axis=1, join='inner').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbebf0-3e67-4fe3-983d-0fb3f2144b28",
   "metadata": {},
   "source": [
    "## Make the table for Jensen-Shannon Distance for non Yes/No question variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd7996cc-aec9-47bb-b237-dae63b97eaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>version</th>\n",
       "      <th>model_name</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>js_dist</th>\n",
       "      <th>kl_div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12100</th>\n",
       "      <td>Vehicle Glass I</td>\n",
       "      <td>unambiguous_uncovered</td>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>0.062967</td>\n",
       "      <td>0.016228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title                version                  model_name  \\\n",
       "12100  Vehicle Glass I  unambiguous_uncovered  Ministral-8B-Instruct-2410   \n",
       "\n",
       "        prompt_type   js_dist    kl_div  \n",
       "12100  disagreement  0.062967  0.016228  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divergences = op.calculate_relative_measures(combined_df)\n",
    "divergences.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa7bd341-b810-4a3f-b730-f8186936d5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0m/231b9j890r542zfr6djkqlz40000gp/T/ipykernel_9819/4163965735.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ).groupby(['model_name'], as_index=False, sort=False).apply(lambda x: x.loc[x[\"Mean\"].idxmax(), :])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>Agr. w/ Neg.</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.033502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>N/Y</td>\n",
       "      <td>0.244847</td>\n",
       "      <td>0.031106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>Agr. w/ Neg.</td>\n",
       "      <td>0.185209</td>\n",
       "      <td>0.055686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.260064</td>\n",
       "      <td>0.050909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.095668</td>\n",
       "      <td>0.051488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.277773</td>\n",
       "      <td>0.027844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.3-70B-Instruct</td>\n",
       "      <td>Negation</td>\n",
       "      <td>0.329654</td>\n",
       "      <td>0.167655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>Disagr. w/ Neg.</td>\n",
       "      <td>0.166143</td>\n",
       "      <td>0.019285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OLMo-2-1124-7B</td>\n",
       "      <td>Disagr. w/ Neg.</td>\n",
       "      <td>0.382940</td>\n",
       "      <td>0.052281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OLMo-2-1124-7B-Instruct</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.532485</td>\n",
       "      <td>0.115830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>Options</td>\n",
       "      <td>0.250857</td>\n",
       "      <td>0.026262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>Options F.</td>\n",
       "      <td>0.134082</td>\n",
       "      <td>0.041130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gemma-7b-it</td>\n",
       "      <td>Options</td>\n",
       "      <td>0.762098</td>\n",
       "      <td>0.036062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai-gpt-4</td>\n",
       "      <td>Negation</td>\n",
       "      <td>0.169361</td>\n",
       "      <td>0.152490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model          Variant      Mean       Std\n",
       "0                 Llama-3.2-1B     Agr. w/ Neg.  0.234301  0.033502\n",
       "1        Llama-3.2-1B-Instruct              N/Y  0.244847  0.031106\n",
       "2                 Llama-3.2-3B     Agr. w/ Neg.  0.185209  0.055686\n",
       "3        Llama-3.2-3B-Instruct       Options F.  0.260064  0.050909\n",
       "4                 Llama-3.1-8B       Options F.  0.095668  0.051488\n",
       "5        Llama-3.1-8B-Instruct       Options F.  0.277773  0.027844\n",
       "6       Llama-3.3-70B-Instruct         Negation  0.329654  0.167655\n",
       "7                  gpt2-medium  Disagr. w/ Neg.  0.166143  0.019285\n",
       "8               OLMo-2-1124-7B  Disagr. w/ Neg.  0.382940  0.052281\n",
       "9      OLMo-2-1124-7B-Instruct       Options F.  0.532485  0.115830\n",
       "10  Ministral-8B-Instruct-2410          Options  0.250857  0.026262\n",
       "11                    gemma-7b       Options F.  0.134082  0.041130\n",
       "12                 gemma-7b-it          Options  0.762098  0.036062\n",
       "13                openai-gpt-4         Negation  0.169361  0.152490"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance_variant_for_model = divergences.groupby(['model_name', 'prompt_type'], as_index=False, sort=False).aggregate(\n",
    "    Mean = pd.NamedAgg('js_dist', \"mean\"),\n",
    "    Std = pd.NamedAgg('js_dist', \"std\")\n",
    ").groupby(['model_name'], as_index=False, sort=False).apply(lambda x: x.loc[x[\"Mean\"].idxmax(), :])\n",
    "max_distance_variant_for_model = max_distance_variant_for_model.rename({'model_name' : 'Model', 'prompt_type': 'Variant'}, axis=1)\n",
    "max_distance_variant_for_model = max_distance_variant_for_model.replace(\n",
    "    {\n",
    "        \"agreement_negation\": \"Agr. w/ Neg.\", \n",
    "        \"no_or_yes\": \"N/Y\", \n",
    "        \"disagreement_negation\": \"Disagr. w/ Neg.\", \n",
    "        \"options_flipped\": \"Options F.\", \n",
    "        \"options\": \"Options\", \n",
    "        \"negation\": \"Negation\",\n",
    "    }\n",
    ")\n",
    "max_distance_variant_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bec5763-167a-4b6d-aede-5765ee924577",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance_variant_for_model.to_latex(\"reports/robustness-prompt-type-distance.tex\", float_format=\"%0.2f\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prej-prompt",
   "language": "python",
   "name": "prej-prompt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
